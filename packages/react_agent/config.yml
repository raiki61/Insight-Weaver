ollama:
  base_url: "${OLLAMA_BASE_URL}"
  model_name: "${OLLAMA_MODEL_NAME}"
  temperature: 1.0

chat_compression:
  context_percentage_threshold: 0.7

mcp_servers:
  servers:
    sample_server:
      transport: streamable_http
      url: http://localhost:8000/mcp/

